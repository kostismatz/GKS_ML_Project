{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 4.0\n",
    "N_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def load_audio(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    y, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    if len(y) > N_SAMPLES:\n",
    "        y = y[:N_SAMPLES]\n",
    "    else:\n",
    "        y = np.pad(y, (0, N_SAMPLES - len(y)))\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def extract_features(y):\n",
    "    features = []\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=SAMPLE_RATE, n_mfcc=20)\n",
    "    features.extend(np.mean(mfcc, axis=1))\n",
    "    features.extend(np.std(mfcc, axis=1))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=SAMPLE_RATE)\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=SAMPLE_RATE)\n",
    "    features.append(np.mean(spec_centroid))\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features.append(np.mean(rms))\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "ROOT = r\"C:\\Users\\kosti\\Desktop\\files\\ml\\assignement\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for fold in os.listdir(ROOT):\n",
    "    fold_path = os.path.join(ROOT, fold)\n",
    "\n",
    "    for file in os.listdir(fold_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            label = file.split('-')[1]   # UrbanSound naming\n",
    "            path = os.path.join(fold_path, file)\n",
    "\n",
    "            audio = load_audio(path)\n",
    "            features = extract_features(audio)\n",
    "\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Dataset:\", X.shape, y.shape)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    stratify=y_encoded,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "models = {\n",
    "    # Linear\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"Perceptron\": Perceptron(max_iter=1000),\n",
    "\n",
    "    # SVM\n",
    "    \"SVM-RBF\": SVC(kernel=\"rbf\"),\n",
    "\n",
    "    # Bayesian / Discriminant\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    # Instance-based\n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "\n",
    "    # Trees\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200),\n",
    "\n",
    "    # Boosting\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(np.unique(y_train)),\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"f1_macro\"\n",
    "    )\n",
    "\n",
    "    results[name] = (scores.mean(), scores.std())\n",
    "    print(f\"{name:20s} | F1-macro: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "best_model_name = max(results, key=lambda k: results[k][0])\n",
    "print(\"\\nBest model:\", best_model_name)\n",
    "\n",
    "best_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", models[best_model_name])\n",
    "])\n",
    "\n",
    "best_pipe.fit(X_train, y_train)\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=le.classes_\n",
    "))\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(np.unique(y_train)),\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_base.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "importances = xgb_base.feature_importances_\n",
    "\n",
    "print(\"Total features:\", X_train.shape[1])\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "K = 30   # δοκίμασε 20, 30, 40\n",
    "top_idx = np.argsort(importances)[-K:]\n",
    "\n",
    "X_train_fs = X_train[:, top_idx]\n",
    "X_test_fs  = X_test[:, top_idx]\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400],\n",
    "    \"max_depth\": [3, 5, 7, 9],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "xgb_tune = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(np.unique(y_train)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_tune,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train_fs, y_train)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_xgb.predict(X_test_fs)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=le.classes_\n",
    "))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    xticklabels=le.classes_,\n",
    "    yticklabels=le.classes_,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "importance = best_xgb.feature_importances_\n",
    "\n",
    "top = np.argsort(importance)[-10:]\n",
    "print(\"Top features:\", top)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "for cls, acc in zip(le.classes_, per_class_acc):\n",
    "    print(f\"{cls:20s} | Accuracy: {acc:.2f}\")\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "error_dict = {}\n",
    "for i, cls_true in enumerate(le.classes_):\n",
    "    errors = {}\n",
    "    for j, cls_pred in enumerate(le.classes_):\n",
    "        if i != j and cm[i,j] > 0:\n",
    "            errors[cls_pred] = cm[i,j]\n",
    "    error_dict[cls_true] = errors\n",
    "\n",
    "error_dict\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d0e79cb5a321f376"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
